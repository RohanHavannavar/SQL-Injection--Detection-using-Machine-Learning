{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.8 Featurizing text data or Given SQL Queries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential libararies\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Query</th>\n",
       "      <th>Label</th>\n",
       "      <th>query_len</th>\n",
       "      <th>num_words_query</th>\n",
       "      <th>no_single_qts</th>\n",
       "      <th>no_double_qts</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_single_cmnt</th>\n",
       "      <th>no_mult_cmnt</th>\n",
       "      <th>no_space</th>\n",
       "      <th>no_perc</th>\n",
       "      <th>no_log_opt</th>\n",
       "      <th>no_arith</th>\n",
       "      <th>no_null</th>\n",
       "      <th>no_hexa</th>\n",
       "      <th>no_alpha</th>\n",
       "      <th>no_digit</th>\n",
       "      <th>len_of_chr_char_null</th>\n",
       "      <th>genuine_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\" or pg_sleep  (  __time__  )  --</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>create user name identified by pass123 tempora...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and 1  =  utl_inaddr.get_host_address   (    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>select * from users where id  =  '1' or @ @1 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>select * from users where id  =  1 or 1#\"  ( ...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Query  Label  \\\n",
       "0           0                  \" or pg_sleep  (  __time__  )  --      1   \n",
       "1           1  create user name identified by pass123 tempora...      1   \n",
       "2           2   and 1  =  utl_inaddr.get_host_address   (    ...      1   \n",
       "3           3   select * from users where id  =  '1' or @ @1 ...      1   \n",
       "4           4   select * from users where id  =  1 or 1#\"  ( ...      1   \n",
       "\n",
       "   query_len  num_words_query  no_single_qts  no_double_qts  no_punct  \\\n",
       "0         33                7              0              1        10   \n",
       "1         90               12              0              0         1   \n",
       "2        218               35              3              0        25   \n",
       "3         90               20              3              0        13   \n",
       "4         85               18              0              1        10   \n",
       "\n",
       "   no_single_cmnt  no_mult_cmnt  no_space  no_perc  no_log_opt  no_arith  \\\n",
       "0               1             0         6        0           1         2   \n",
       "1               0             0        11        0           0         0   \n",
       "2               0             0        35        0           2         0   \n",
       "3               1             0        20        0           1         3   \n",
       "4               1             0        18        0           1         3   \n",
       "\n",
       "   no_null  no_hexa  no_alpha  no_digit  len_of_chr_char_null  \\\n",
       "0        0        0        13         0                     0   \n",
       "1        0        0        75         3                     0   \n",
       "2        0        0       120         2                     0   \n",
       "3        0        0        42         5                     0   \n",
       "4        0        0        42         4                     0   \n",
       "\n",
       "   genuine_keywords  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the preprocessed data\n",
    "data = pd.read_csv('feature_extracted_1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.8.1 Splitting the dataset to train and test </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size is (21523, 19)\n",
      "test dataset size is (9225, 19)\n"
     ]
    }
   ],
   "source": [
    "#will split the datset in 70 and 30 i.e 70 percent for training and 30 percent for test\n",
    "#since the class is imbalanced will do stratify sampling\n",
    "\n",
    "#will remove the target variable i.e label column from datset\n",
    "y = data['Label']\n",
    "x = data.drop('Label',axis = 1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,stratify = y)\n",
    "\n",
    "print(\"train dataset size is {}\".format(x_train.shape))\n",
    "print(\"test dataset size is {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.8.2 Featurizing text data or Given SQL Queries using Bag of words </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding text data\n",
      "the shape of train dataset unigram is (21523, 18621)\n",
      "the shape of test dataset unigram is  (9225, 18621)\n"
     ]
    }
   ],
   "source": [
    "#using countvectorizer for bag of words\n",
    "#using bag of words for unigram range\n",
    "\n",
    "unigram_bow = CountVectorizer(ngram_range = (1,1))\n",
    "train_bow = unigram_bow.fit(x_train['Query'].values)\n",
    "\n",
    "\n",
    "print(\"After Encoding text data\")\n",
    "x_train_bow_unigram = train_bow.transform(x_train['Query'].values)\n",
    "x_test_bow_unigram = train_bow.transform(x_test['Query'].values)\n",
    "\n",
    "\n",
    "print(\"the shape of train dataset unigram is {}\".format(x_train_bow_unigram.shape))\n",
    "print(\"the shape of test dataset unigram is  {}\".format(x_test_bow_unigram.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding text data\n",
      "the shape of train dataset unigram is (21523, 52073)\n",
      "the shape of test dataset unigram is  (9225, 52073)\n"
     ]
    }
   ],
   "source": [
    "#will use bigram range of values to build bow\n",
    "bigram_bow = CountVectorizer(ngram_range = (2,2))\n",
    "train_bigram_bow = bigram_bow.fit(x_train['Query'].values)\n",
    "\n",
    "print(\"After Encoding text data\")\n",
    "x_train_bow_bigram = train_bigram_bow.transform(x_train['Query'].values)\n",
    "x_test_bow_bigram = train_bigram_bow.transform(x_test['Query'].values)\n",
    "\n",
    "\n",
    "print(\"the shape of train dataset unigram is {}\".format(x_train_bow_bigram.shape))\n",
    "print(\"the shape of test dataset unigram is  {}\".format(x_test_bow_bigram.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding text data\n",
      "the shape of train dataset unigram is (21523, 70694)\n",
      "the shape of test dataset unigram is  (9225, 70694)\n"
     ]
    }
   ],
   "source": [
    "#will use combined i.e unigram + bigram words\n",
    "combine_bow = CountVectorizer(ngram_range = (1,2))\n",
    "combine_train_bow = combine_bow.fit(x_train['Query'].values)\n",
    "\n",
    "\n",
    "print(\"After Encoding text data\")\n",
    "x_train_bow_combine = combine_train_bow.transform(x_train['Query'].values)\n",
    "x_test_bow_combine = combine_train_bow.transform(x_test['Query'].values)\n",
    "\n",
    "\n",
    "print(\"the shape of train dataset unigram is {}\".format(x_train_bow_combine.shape))\n",
    "print(\"the shape of test dataset unigram is  {}\".format(x_test_bow_combine.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.8.3 Featurizing text data or Given SQL Queries using tfidf vectorizer </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding text data\n",
      "the shape of train dataset unigram is (21523, 18621)\n",
      "the shape of test dataset unigram is  (9225, 18621)\n"
     ]
    }
   ],
   "source": [
    "#considering only unigrams\n",
    "tfidf_bow = TfidfVectorizer(ngram_range = (1,1))\n",
    "tfidf_train_bow = tfidf_bow.fit(x_train['Query'].values)\n",
    "\n",
    "\n",
    "print(\"After Encoding text data\")\n",
    "x_train_tfidf_unigram = tfidf_train_bow.transform(x_train['Query'].values)\n",
    "x_test_tfidf_unigram = tfidf_train_bow.transform(x_test['Query'].values)\n",
    "\n",
    "\n",
    "print(\"the shape of train dataset unigram is {}\".format(x_train_tfidf_unigram.shape))\n",
    "print(\"the shape of test dataset unigram is  {}\".format(x_test_tfidf_unigram.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding text data\n",
      "the shape of train dataset unigram is (21523, 52073)\n",
      "the shape of test dataset unigram is  (9225, 52073)\n"
     ]
    }
   ],
   "source": [
    "#considering only bigrams\n",
    "tfidf = TfidfVectorizer(ngram_range = (2,2))\n",
    "tfidf_train_bigram = tfidf.fit(x_train['Query'].values)\n",
    "\n",
    "\n",
    "print(\"After Encoding text data\")\n",
    "x_train_tfidf_bigram = tfidf_train_bigram.transform(x_train['Query'].values)\n",
    "x_test_tfidf_bigram = tfidf_train_bigram.transform(x_test['Query'].values)\n",
    "\n",
    "\n",
    "print(\"the shape of train dataset unigram is {}\".format(x_train_tfidf_bigram.shape))\n",
    "print(\"the shape of test dataset unigram is  {}\".format(x_test_tfidf_bigram.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding text data\n",
      "the shape of train dataset unigram is (21523, 70694)\n",
      "the shape of test dataset unigram is  (9225, 70694)\n"
     ]
    }
   ],
   "source": [
    "#combining unigram + bigram\n",
    "tfidf_combine = TfidfVectorizer(ngram_range = (1,2))\n",
    "tfidf_train_combine = tfidf_combine.fit(x_train['Query'].values)\n",
    "\n",
    "\n",
    "print(\"After Encoding text data\")\n",
    "x_train_tfidf_combine = tfidf_train_combine.transform(x_train['Query'].values)\n",
    "x_test_tfidf_combine = tfidf_train_combine.transform(x_test['Query'].values)\n",
    "\n",
    "\n",
    "print(\"the shape of train dataset unigram is {}\".format(x_train_tfidf_combine.shape))\n",
    "print(\"the shape of test dataset unigram is  {}\".format(x_test_tfidf_combine.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.8.4 Featurizing text data or Given SQL Queries using Average word2vec </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.8.4.1 Using pretrained Glove vectors for words Embeddings </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading glove vector file\n",
    "with open('glove_vectors', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    glove_words =  set(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 30748/30748 [00:00<00:00, 67055.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30748\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#compute average word2vec for each query\n",
    "avg_w2v_vectors = [] \n",
    "for sentence in tqdm(data['Query'].values): \n",
    "    vector = np.zeros(300) \n",
    "    cnt_words =0\n",
    "    for word in sentence.split(): \n",
    "        if word in glove_words:\n",
    "            vector += model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    avg_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(avg_w2v_vectors))\n",
    "print(len(avg_w2v_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.8.5 Featurizing text data or Given SQL Queries using Tfidf weighted word2vec </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(data['Query'].values)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 30748/30748 [00:01<00:00, 29347.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30748\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#computing tfidf word2vec for each query\n",
    "tfidf_w2v_vectors = []\n",
    "for sentence in tqdm(data['Query'].values):\n",
    "    vector = np.zeros(300)\n",
    "    tf_idf_weight =0\n",
    "    for word in sentence.split(): \n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = model[word] \n",
    "           \n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) \n",
    "            vector += (vec * tf_idf)\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors.append(vector)\n",
    "\n",
    "print(len(tfidf_w2v_vectors))\n",
    "print(len(tfidf_w2v_vectors[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
